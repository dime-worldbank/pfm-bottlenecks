{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "24ed5424-bab3-422d-8d72-21338d5560fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Structured Pipeline - Main Notebook\n",
    "## PFM Bottleneck Analysis Pipeline\n",
    "\n",
    "This notebook demonstrates the structured pipeline approach for bottleneck identification and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78300a9d-80da-494a-9e87-8b17cb3c8649",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6acdcc57-e207-4ecc-a238-f4d04df93955",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install instructor\n",
    "!pip install azure.identity openai\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c4e3a28-3269-40c0-a134-e10d784f9a68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Add the structured_pipeline directory to path\n",
    "sys.path.append('/Workspace/structured_pipeline')\n",
    "\n",
    "# Import pipeline components\n",
    "from core.pipeline import BottleneckPipeline\n",
    "from core.services import AzureOpenAIService\n",
    "from core.config import LLM_MODEL, TEMPERATURE\n",
    "from core.database import DatabaseManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f4f0568-68be-4ecc-a807-d3534be7bedd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Initialize Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3dcf3962-5cba-476d-b3a6-79c2fa420899",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"BottleneckAnalysis\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Initialize services\n",
    "llm_service = AzureOpenAIService()\n",
    "db_manager = DatabaseManager(spark)\n",
    "\n",
    "# Initialize pipeline\n",
    "pipeline = BottleneckPipeline(llm_service, db_manager)\n",
    "\n",
    "print(\"Pipeline initialized successfully\")\n",
    "print(f\"Using model: {LLM_MODEL}\")\n",
    "print(f\"Temperature: {TEMPERATURE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c644403-74e5-4f8c-944b-da423910602a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "27ed46ca-97d3-4550-9b9e-0b179cca6a64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define input parameters\n",
    "COUNTRY_CODES = ['MLI', 'BFA']  # Mali and Burkina Faso\n",
    "MIN_CHUNK_LENGTH = 1000\n",
    "\n",
    "# Load chunks from database\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    c.document_id,\n",
    "    c.chunk_id,\n",
    "    c.chunk_text,\n",
    "    c.page_number,\n",
    "    d.document_name,\n",
    "    d.country_code\n",
    "FROM prd_mega.sboost4.per_pfr_chunks c\n",
    "JOIN prd_corpdata.dm_reference_gold.v_dim_imagebank_document d\n",
    "    ON c.document_id = d.document_id\n",
    "WHERE d.country_code IN ({','.join([f\"'{cc}'\" for cc in COUNTRY_CODES])})\n",
    "    AND LENGTH(c.chunk_text) >= {MIN_CHUNK_LENGTH}\n",
    "    AND d.document_type IN ('PER', 'PFR')\n",
    "ORDER BY c.document_id, c.chunk_id\n",
    "\"\"\"\n",
    "\n",
    "df_chunks = spark.sql(query).toPandas()\n",
    "print(f\"Loaded {len(df_chunks)} chunks from {df_chunks['document_id'].nunique()} documents\")\n",
    "print(f\"Countries: {df_chunks['country_code'].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "81e6fa9f-5104-4709-abf2-0c361232c5f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "df_chunks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45afc591-d6f1-414d-b952-85586cd2ef58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Select Bottleneck to Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4542fd2-ef8b-4329-a41a-dfdbe145ac40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# List available bottlenecks\n",
    "available_bottlenecks = pipeline.list_bottlenecks()\n",
    "\n",
    "print(\"Available bottlenecks:\")\n",
    "for bottleneck_id, info in available_bottlenecks.items():\n",
    "    print(f\"  {bottleneck_id}: {info['name']}\")\n",
    "    print(f\"    Description: {info['description'][:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "321e3b19-a255-4316-be29-5558e5ef8d9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select bottleneck to process\n",
    "BOTTLENECK_ID = \"1.1\"  # Change this to process different bottlenecks\n",
    "\n",
    "print(f\"Selected bottleneck: {BOTTLENECK_ID}\")\n",
    "print(f\"Name: {available_bottlenecks[BOTTLENECK_ID]['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8237481d-62c8-4a82-9991-1e79f9e4b624",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Stage 1: Extraction\n",
    "\n",
    "Extract potential evidence from document chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "168567df-6001-4c8d-ab86-15e58f2987de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Option 1: Process a sample for testing\n",
    "SAMPLE_SIZE = 10  # Adjust as needed\n",
    "df_sample = df_chunks.sample(n=min(SAMPLE_SIZE, len(df_chunks)), random_state=42)\n",
    "\n",
    "print(f\"Processing {len(df_sample)} chunks for bottleneck {BOTTLENECK_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "96194ad1-c281-4ee3-9f8c-ab52c322e970",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run extraction\n",
    "df_extracted = pipeline.run_extraction(\n",
    "    bottleneck_id=BOTTLENECK_ID,\n",
    "    chunks=df_sample.to_dict('records'),\n",
    "    save_to_db=False  # Set to True to save to database\n",
    ")\n",
    "\n",
    "print(f\"\\nExtraction complete:\")\n",
    "print(f\"  Total chunks processed: {len(df_sample)}\")\n",
    "print(f\"  Chunks with evidence: {len(df_extracted)}\")\n",
    "print(f\"  Extraction rate: {len(df_extracted)/len(df_sample)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc9d5b0a-0a3b-43f7-8509-3d99faa049e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# View extracted evidence\n",
    "if len(df_extracted) > 0:\n",
    "    print(\"Sample of extracted evidence:\")\n",
    "    for idx, row in df_extracted.head(3).iterrows():\n",
    "        print(f\"\\n--- Evidence {idx+1} ---\")\n",
    "        print(f\"Document: {row['document_name'][:50]}...\")\n",
    "        print(f\"Evidence: {row['evidence_text'][:200]}...\")\n",
    "        print(f\"Relevance: {row['relevance_score']:.2f}\")\n",
    "        print(f\"Reasoning: {row['reasoning'][:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5e84d8a8-470e-4980-8d07-0e0174a74a40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Stage 2: Validation\n",
    "\n",
    "Validate extracted evidence using detailed criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01def796-a28a-4909-977a-1f946a60fb39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run validation on extracted evidence\n",
    "if len(df_extracted) > 0:\n",
    "    df_validated = pipeline.run_validation(\n",
    "        bottleneck_id=BOTTLENECK_ID,\n",
    "        df_extracted=df_extracted,\n",
    "        save_to_db=False  # Set to True to save to database\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nValidation complete:\")\n",
    "    print(f\"  Evidence validated: {len(df_validated)}\")\n",
    "    print(f\"  Validated as relevant: {df_validated['is_valid'].sum()}\")\n",
    "    print(f\"  Validation rate: {df_validated['is_valid'].mean()*100:.1f}%\")\n",
    "else:\n",
    "    print(\"No evidence to validate\")\n",
    "    df_validated = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92d89c9b-214a-4230-9fc1-4501b084346f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# View validation results\n",
    "if len(df_validated) > 0:\n",
    "    print(\"\\nValidation summary:\")\n",
    "    print(df_validated[['document_name', 'evidence_text', 'is_valid', 'confidence', 'validation_reasoning']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54249380-19f0-4b44-a43e-6d5b15031ae1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Stage 3: Formatting\n",
    "\n",
    "Format validated evidence for output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "221512da-082d-4076-b5e5-787f73ecd849",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run formatting on validated evidence\n",
    "if len(df_validated[df_validated['is_valid']]) > 0:\n",
    "    df_formatted = pipeline.run_formatting(\n",
    "        bottleneck_id=BOTTLENECK_ID,\n",
    "        df_validated=df_validated[df_validated['is_valid']],\n",
    "        save_to_db=False  # Set to True to save to database\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nFormatting complete:\")\n",
    "    print(f\"  Evidence formatted: {len(df_formatted)}\")\n",
    "else:\n",
    "    print(\"No valid evidence to format\")\n",
    "    df_formatted = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db2005fe-00c0-4df6-a021-f71f01b0a6c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# View formatted output\n",
    "if len(df_formatted) > 0:\n",
    "    print(\"\\nFormatted evidence summary:\")\n",
    "    for idx, row in df_formatted.head(2).iterrows():\n",
    "        print(f\"\\n--- Final Evidence {idx+1} ---\")\n",
    "        print(f\"Summary: {row['summary']}\")\n",
    "        print(f\"Key Points: {row['key_points']}\")\n",
    "        print(f\"Document: {row['document_name']}\")\n",
    "        print(f\"Page: {row['page_number']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9943131-a2d8-407c-909d-0dc64a538f9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Full Pipeline Execution\n",
    "\n",
    "Run all stages sequentially with database persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "736790b8-e522-428c-995b-0362204189b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run full pipeline for a bottleneck\n",
    "def run_full_pipeline(bottleneck_id, chunks_df, save_to_db=True):\n",
    "    \"\"\"\n",
    "    Run complete pipeline for a single bottleneck\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Running full pipeline for bottleneck {bottleneck_id}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Stage 1: Extraction\n",
    "    print(\"\\n[Stage 1] Extraction...\")\n",
    "    df_extracted = pipeline.run_extraction(\n",
    "        bottleneck_id=bottleneck_id,\n",
    "        chunks=chunks_df.to_dict('records'),\n",
    "        save_to_db=save_to_db\n",
    "    )\n",
    "    print(f\"  Extracted {len(df_extracted)} pieces of evidence\")\n",
    "    \n",
    "    if len(df_extracted) == 0:\n",
    "        print(\"  No evidence found, stopping pipeline\")\n",
    "        return None, None, None\n",
    "    \n",
    "    # Stage 2: Validation\n",
    "    print(\"\\n[Stage 2] Validation...\")\n",
    "    df_validated = pipeline.run_validation(\n",
    "        bottleneck_id=bottleneck_id,\n",
    "        df_extracted=df_extracted,\n",
    "        save_to_db=save_to_db\n",
    "    )\n",
    "    valid_count = df_validated['is_valid'].sum()\n",
    "    print(f\"  Validated {valid_count}/{len(df_validated)} as relevant\")\n",
    "    \n",
    "    if valid_count == 0:\n",
    "        print(\"  No valid evidence, stopping pipeline\")\n",
    "        return df_extracted, df_validated, None\n",
    "    \n",
    "    # Stage 3: Formatting\n",
    "    print(\"\\n[Stage 3] Formatting...\")\n",
    "    df_formatted = pipeline.run_formatting(\n",
    "        bottleneck_id=bottleneck_id,\n",
    "        df_validated=df_validated[df_validated['is_valid']],\n",
    "        save_to_db=save_to_db\n",
    "    )\n",
    "    print(f\"  Formatted {len(df_formatted)} final evidence pieces\")\n",
    "    \n",
    "    return df_extracted, df_validated, df_formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05aeb96b-f749-4e4c-9b8d-83d323c446ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Run full pipeline on sample data\n",
    "FULL_PIPELINE_SAMPLE = 50  # Adjust size as needed\n",
    "df_full_sample = df_chunks.sample(n=min(FULL_PIPELINE_SAMPLE, len(df_chunks)), random_state=42)\n",
    "\n",
    "results = run_full_pipeline(\n",
    "    bottleneck_id=BOTTLENECK_ID,\n",
    "    chunks_df=df_full_sample,\n",
    "    save_to_db=False  # Set to True for production\n",
    ")\n",
    "\n",
    "df_ext, df_val, df_fmt = results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "020b6169-2229-418c-8e87-a06139e90ef4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Batch Processing Multiple Bottlenecks\n",
    "\n",
    "Process multiple bottlenecks sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "78f073b5-10d6-4410-897c-5932e8aef530",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Process multiple bottlenecks\n",
    "BOTTLENECKS_TO_PROCESS = [\"1.1\", \"2.1\", \"3.1\", \"6.1\"]\n",
    "BATCH_SIZE = 100  # Number of chunks per bottleneck\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for bottleneck_id in BOTTLENECKS_TO_PROCESS:\n",
    "    print(f\"\\n\\n{'#'*70}\")\n",
    "    print(f\"Processing Bottleneck {bottleneck_id}\")\n",
    "    print(f\"{'#'*70}\")\n",
    "    \n",
    "    # Get sample for this bottleneck\n",
    "    df_batch = df_chunks.sample(n=min(BATCH_SIZE, len(df_chunks)), random_state=42)\n",
    "    \n",
    "    # Run pipeline\n",
    "    results = run_full_pipeline(\n",
    "        bottleneck_id=bottleneck_id,\n",
    "        chunks_df=df_batch,\n",
    "        save_to_db=False\n",
    "    )\n",
    "    \n",
    "    all_results[bottleneck_id] = results\n",
    "    \n",
    "print(\"\\n\\n\" + \"=\"*70)\n",
    "print(\"BATCH PROCESSING COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "39240efd-64bf-4909-9691-e153446ba4dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary of batch results\n",
    "print(\"\\nBatch Processing Summary:\")\n",
    "print(\"-\"*50)\n",
    "\n",
    "for bottleneck_id, (df_ext, df_val, df_fmt) in all_results.items():\n",
    "    print(f\"\\nBottleneck {bottleneck_id}:\")\n",
    "    if df_ext is not None:\n",
    "        print(f\"  Extracted: {len(df_ext)} evidence pieces\")\n",
    "    if df_val is not None:\n",
    "        print(f\"  Validated: {df_val['is_valid'].sum()}/{len(df_val)} as relevant\")\n",
    "    if df_fmt is not None:\n",
    "        print(f\"  Formatted: {len(df_fmt)} final pieces\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "023857db-b319-47b0-853d-4758fdecb7e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Export Results to Excel\n",
    "\n",
    "Export formatted results for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b40e535-5845-4d18-afe9-56ee17627386",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Export results to Excel\n",
    "output_dir = \"/Volumes/prd_mega/sboost4/vboost4/Documents/input/Bottleneck/\"\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "for bottleneck_id, (df_ext, df_val, df_fmt) in all_results.items():\n",
    "    if df_fmt is not None and len(df_fmt) > 0:\n",
    "        output_file = f\"{output_dir}bottleneck_{bottleneck_id}_{timestamp}.xlsx\"\n",
    "        \n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "            df_fmt.to_excel(writer, sheet_name='Final Evidence', index=False)\n",
    "            df_val.to_excel(writer, sheet_name='Validation Details', index=False)\n",
    "            df_ext.to_excel(writer, sheet_name='Extraction Details', index=False)\n",
    "        \n",
    "        print(f\"Exported bottleneck {bottleneck_id} results to: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e60409fb-b0d9-42dc-ae6a-1a5308b8fcde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Monitoring and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a052b9f2-595c-4a5a-a046-5a55199ec8b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Analyze pipeline performance\n",
    "def analyze_pipeline_performance(results_dict):\n",
    "    \"\"\"\n",
    "    Analyze performance metrics across bottlenecks\n",
    "    \"\"\"\n",
    "    metrics = []\n",
    "    \n",
    "    for bottleneck_id, (df_ext, df_val, df_fmt) in results_dict.items():\n",
    "        if df_ext is not None:\n",
    "            extraction_rate = len(df_ext) / BATCH_SIZE if BATCH_SIZE > 0 else 0\n",
    "            validation_rate = df_val['is_valid'].mean() if df_val is not None and len(df_val) > 0 else 0\n",
    "            final_rate = len(df_fmt) / BATCH_SIZE if df_fmt is not None and BATCH_SIZE > 0 else 0\n",
    "            \n",
    "            metrics.append({\n",
    "                'bottleneck_id': bottleneck_id,\n",
    "                'extraction_rate': extraction_rate,\n",
    "                'validation_rate': validation_rate,\n",
    "                'final_rate': final_rate,\n",
    "                'extracted_count': len(df_ext) if df_ext is not None else 0,\n",
    "                'validated_count': df_val['is_valid'].sum() if df_val is not None else 0,\n",
    "                'final_count': len(df_fmt) if df_fmt is not None else 0\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# Generate performance report\n",
    "df_performance = analyze_pipeline_performance(all_results)\n",
    "print(\"Pipeline Performance Analysis:\")\n",
    "print(df_performance.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c69741bf-e24c-4875-9205-11ae7ca4d318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Visualize performance (if matplotlib is available)\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Extraction rates\n",
    "    axes[0].bar(df_performance['bottleneck_id'], df_performance['extraction_rate'])\n",
    "    axes[0].set_title('Extraction Rate by Bottleneck')\n",
    "    axes[0].set_ylabel('Rate')\n",
    "    axes[0].set_ylim(0, 1)\n",
    "    \n",
    "    # Validation rates\n",
    "    axes[1].bar(df_performance['bottleneck_id'], df_performance['validation_rate'])\n",
    "    axes[1].set_title('Validation Rate by Bottleneck')\n",
    "    axes[1].set_ylabel('Rate')\n",
    "    axes[1].set_ylim(0, 1)\n",
    "    \n",
    "    # Final counts\n",
    "    axes[2].bar(df_performance['bottleneck_id'], df_performance['final_count'])\n",
    "    axes[2].set_title('Final Evidence Count by Bottleneck')\n",
    "    axes[2].set_ylabel('Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"Matplotlib not available for visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "083ff01e-6cd9-4735-b469-f08d939ff349",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Clean Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b00a19de-cd27-4eef-a280-0f0b9fb38dff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Clean up resources\n",
    "spark.stop()\n",
    "print(\"Pipeline execution complete. Spark session closed.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "main",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
