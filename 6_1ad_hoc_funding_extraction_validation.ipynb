{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d63df90-7501-4153-95f6-cdfdba341b7a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from service import Service\n",
    "load_dotenv()\n",
    "from typing import List, Literal, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "import math\n",
    "from typing import Dict, Any, List\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from service import Service\n",
    "from consts import DEFAULT_LLM_MODEL\n",
    "service = Service()\n",
    "model_name = DEFAULT_LLM_MODEL\n",
    "\n",
    "\n",
    "system_prompt = '''You are a public financial management (PFM) diagnostic analyst.  \n",
    "Your job is to identify whether a passage provides evidence for Bottleneck 6.1:  \n",
    "“Ad hoc, political, and fragmented funding channels contribute to ineffective and inefficient delivery.”\n",
    "\n",
    "Judge only what is in the text.  \n",
    "1️. Detect **structural fragmentation** — multiple or parallel funding/management channels, off-budget or ad-hoc allocations, donor vs government systems, mid-year or discretionary funding, different rules or processes, etc.  \n",
    "2. Detect **delivery failure or inefficiency** — unpredictability, duplication, coordination failure, arrears, start-stop projects, or high administrative costs.  \n",
    "3️. Apply PFM knowledge: fragmentation is a *diagnostic feature* that normally implies inefficiency, but mark evidence only when cues are clear and quotable.  \n",
    "4️. Follow the output schema exactly; quote trigger spans from the text; abstain if uncertain.\n",
    "\n",
    "Be precise, conservative, and evidence-based.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b26678a9-34ce-4e77-9c88-a1b6f6b46788",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('bottleneck_final_summarized_for_review.xlsx', sheet_name='6.1')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a0408492-472a-4030-90d1-57c0fa10382d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df['Review Result (Relevant, Irrelevant)'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "842607d0-d880-4fa6-a1db-129a6adb8510",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('bottleneck_final_summarized_for_review.xlsx', sheet_name='6.1')\n",
    "df = df[df['Review Result (Relevant, Irrelevant)'].notna()]\n",
    "rel_cols = ['node_id','chunk_id', 'extended_context','extracted_evidence', 'Review Result (Relevant, Irrelevant)',\n",
    "            'Reason for irrelevant or unsure ']\n",
    "df = df[rel_cols]\n",
    "df = df[df['Review Result (Relevant, Irrelevant)'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6d4105cb-c1d0-4140-a9e5-f224cfc3018f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "challenge = '''Unreliable, delayed and fragmented funding for delivery'''\n",
    "bottleneck = '''6.1 Ad hoc, political and fragmented funding channels contribute to ineffective and inefficient delivery'''\n",
    "extended_definition = '''\n",
    "Extended definition: The funding for service delivery and projects might be fragmented due to the existence of different funding sources or channels, such as budget general funds (general non-earmarked funding from the budget) from different ministries/agencies, earmarked funds from transfers coming from other governments, institutions and organizations and from earmarked government revenues, as well as funding coming from donors. Dealing with multiple funding can be challenging, especially if there is not an integrated and consolidated planning and management of such funding (these funds being managed with their corresponding parallel systems). Different management stages and procedures, non-consolidated information about the expected, distributed and consumed funds, as well as different levels of discretion in regard the use of the funds can make difficult a rational policy planning (due to uncertainty and lack of predictability of funding) and implementation, in addition to a more costly administration and higher risks of corruption and funds diversion.     \n",
    "\n",
    "Political discretion on the management of specific funds may create relevant obstacles to adequate planning and execution of service delivery and projects, as it may imply significant levels of uncertainty in regard to the allocated resources. Changing priorities, biases towards new projects and other elements may reduce the predictability and effective availability of funding for specific services and projects, making it difficult for agencies and departments to plan effectively and sustain long-term projects. This volatile nature of funding can lead to start-stop patterns in project execution, for example, where projects are initiated but then stalled due to sudden withdrawals or delays in funding.   \n",
    "\n",
    "The atomization and fragmentation of funding, with different parallel management (with their own stages and processes), reporting mechanisms and information systems contributes to administrative burdens and inefficient delivery, as well as making more difficult ensure a sound coordination, planning and execution of projects. These parallel systems may exist, for example, because of donors' contributions to the financing of specific services or projects, in order to fulfill their own financial management and control and reporting requirements, but at the cost of hindering client government’s systems and the integrated management of funds and service and project planning and coordination.  For example, donor’s use of Ethiopia’s public financial management and procurement systems significantly declined between the middle and end of the decade of 2010, with more than 50% of donor funding routed through parallel systems , creating complexity and lack of integration of services funding. Alike, in Uganda and Indonesia, the existence of multiple fragmented sources of financing created major challenges for local government planning, budget formulation and execution in regard of education policies.   \n",
    "\n",
    "In addition, the effects of the fragmentation of the different funding channels can foster, and be amplified, by the lack of adequate coordination between sectors, levels of government and partners, resulting in a duplication of efforts, and inefficiencies on the allocation, channeling and execution of resources.  For example, different agencies might end up competing for the same funds or, conversely, some funds might remain underutilized due to lack of awareness or coordination among potential beneficiaries, or, for policies planned and executed across different agencies and levels of government, poor coordination may end up with an inefficient policy development and allocation of resources (not coordinated planned actions and prepared budgets towards common/shared policy goals), as well as with delays and/or shortages in regard the distribution of funds. For instance, in Rwanda108, the funding and the implementation of gender-based violence policies managed by many agencies across the government (at least four ministries) and district governments, largely relying on donors funding, and with non-public funded services provided by outside of government institutions, organizations and communities, resulting challenging in terms of policy integration and optimal management of resources. Particularly relevant and frequent might be the case of fragmented and uncoordinated different funding mechanisms across levels of governments. In Nigeria health financing streams were highly fragmented across and within levels of government, with health facilities receiving both federal and state resources, contributory health insurance schemes being managed by separate small pools, with the Basic Healthcare Provision Fund creates even more funding pools managed by state and insurance agencies, setting up a very complex system between different levels of governments and operators. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "99f36f83-0b87-46ad-8570-c5f6980a9fb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a PFM diagnostic coder. Your task is to judge whether the INPUT TEXT\n",
    "contains evidence for a Bottleneck classified under the larger topic: {challenge}.\n",
    "\n",
    "The specific bottleneck is defined as: {bottleneck}.\n",
    "\n",
    "An extended definition with more context is given below:\n",
    "\n",
    "{extended_definition}\n",
    "\n",
    "Output MUST follow the JSON schema you are given (no extra keys, no prose).\n",
    "\n",
    "––––– SCOPE LOCK (IMPORTANT) –––––\n",
    "Treat fragmentation strictly as **funding/financial-management channel fragmentation**.\n",
    "Program/administrative separation is irrelevant **unless** it creates a **distinct funding flow or a\n",
    "parallel financial control stream** (e.g., separate accounts, off-budget handling, different release/disbursement rules).\n",
    "\n",
    "––––– DEFINITIONS (OPERABLE) –––––\n",
    "• Fragmentation cues (diagnostic features) — funding/finance anchored:\n",
    "  STRONG (any ONE is sufficient for feature-based evidence):\n",
    "    - off-budget flows (outside the main budget/TSA/IFMIS); parallel accounts/systems\n",
    "    - donor vs government **follow different rules/processes** (allocation/release/procurement/reporting)\n",
    "    - political/ad-hoc channels bypassing normal process (e.g., block/discretionary funds, mid-year approvals outside ADP/MTEF)\n",
    "    - multiple **financing pools** for the same service managed by different agencies\n",
    "    - explicit bypass of government systems; pooled fund dissolved → parallel handling\n",
    "  MODERATE (need TWO together if no STRONG):\n",
    "    - earmarked/tied funds with separate handling\n",
    "    - vertical (intergovernmental) fragmentation with **distinct pools** (federal/state/insurer)\n",
    "    - procedural divergence across **funding streams** (release/reporting/procurement/IFMIS)\n",
    "    - volatility explicitly revealing separate handling (e.g., “moved off-budget”, “bypassed TSA”)\n",
    "\n",
    "• Delivery failure / inefficiency (consequences):\n",
    "  - higher administrative costs/inefficiency/duplication\n",
    "  - unpredictability/volatility in funding; start–stop projects\n",
    "  - coordination failures (duplication, underutilization, competition for funds)\n",
    "  - delays/arrears/cash shortfalls\n",
    "  - corruption/leakage risk\n",
    "\n",
    "––––– HARD NEGATIVES (EXCLUDE) –––––\n",
    "If the text is ONLY about any of the following (with no qualifying funding-channel cue), set hard_negative=true and decision=\"irrelevant\":\n",
    "  - wage-bill/personnel/payroll control (PSC, hiring discretion, casual workers, **separate budget vote/line**) **on-budget**\n",
    "  - generic program-budget/accountability structure (e.g., “draws from multiple subprograms”) without distinct funding channels/systems\n",
    "  - capacity/procurement/audit findings without alternate channels\n",
    "  - revenue politics (divisible pool shares, opposing OSR reforms) **without** off-budget/ad-hoc fees/parallel accounts\n",
    "  - donor dependence/withdrawal **without** off-budget/parallel handling or different rules\n",
    "\n",
    "––––– TRIGGER SPAN REQUIREMENT –––––\n",
    "Before labeling Relevant, extract verbatim **finance trigger spans** from the INPUT TEXT (not the context) that reference money-flow/control terms such as:\n",
    "  “off-budget”, “TSA”, “IFMIS”, “parallel account/system”, “pooled fund/pool”, “allocation”, “release”, “warrant”,\n",
    "  “disbursement”, “on-budget”, “block/discretionary fund”, “mid-year approval”, “ADP/MTEF”, “donor-funded vs government-funded (different rules)”.\n",
    "\n",
    "––––– ACCEPTANCE RULES –––––\n",
    "1) is_fragmentation_evidence = true  iff\n",
    "   ((STRONG >= 1) OR (MODERATE >= 2)) AND trigger_spans (finance words) nonempty AND hard_negative = false.\n",
    "2) is_fragmentation_plus_failure = true  iff\n",
    "   is_fragmentation_evidence = true AND failure_present = true.\n",
    "3) If no explicit **finance** phrase can be quoted for trigger_spans, set decision to \"abstain\" (even if you suspect relevance).\n",
    "4) Always fill trigger_spans and failure_spans with verbatim phrases from the INPUT TEXT that justify your labels.\n",
    "\n",
    "––––– OUTPUT FORMAT –––––\n",
    "Return ONLY JSON that conforms to the schema provided below. Do not include commentary.\n",
    "\n",
    "––––– INPUT TEXT –––––\n",
    "{input_text}\n",
    "\n",
    "This input text is extracted from the following extended source context. Use it only for corroboration (do not quote from it):\n",
    "{extended_context}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "StrongCue = Literal[\n",
    "    \"off_budget\",\n",
    "    \"parallel_systems\",\n",
    "    \"separate_administration\",\n",
    "    \"different_rules_processes_across_streams\",\n",
    "    \"political_ad_hoc_allocation\",\n",
    "    \"mid_year_approval_outside_cycle\",\n",
    "    \"block_allocation_outside_process\",\n",
    "    \"multiple_financing_pools_different_agencies\",\n",
    "]\n",
    "\n",
    "ModerateCue = Literal[\n",
    "    \"earmarked_or_tied_grants\",\n",
    "    \"vertical_fragmentation_intergovernmental\",\n",
    "    \"procedural_divergence_reporting_procurement_ifmis\",\n",
    "    \"pooled_fund_dissolved_or_bypass\",\n",
    "    \"volatility_revealing_fragmentation\",\n",
    "]\n",
    "\n",
    "FailureType = Literal[\n",
    "    \"inefficiency_higher_admin_costs\",\n",
    "    \"unpredictability_funding_volatility\",\n",
    "    \"coordination_failure_duplication_underutilization_competition\",\n",
    "    \"delays_start_stop\",\n",
    "    \"arrears_or_cash_shortfalls\",\n",
    "    \"corruption_or_leakage_risk\",\n",
    "]\n",
    "\n",
    "Subtype = Literal[\n",
    "    \"donor_gov_parallel\",\n",
    "    \"domestic_vs_donor_different_rules\",\n",
    "    \"political_ad_hoc_intragovernment\",\n",
    "    \"vertical_intergovernmental_fragmentation\",\n",
    "    \"program_administration_fragmentation\",\n",
    "    \"other\",\n",
    "]\n",
    "\n",
    "Decision = Literal[\n",
    "    \"relevant_feature\",                 # feature-based evidence satisfied\n",
    "    \"relevant_feature_and_failure\",     # fragmentation + failure satisfied\n",
    "    \"irrelevant\",                       # hard negative or no cues\n",
    "    \"abstain\",                          # insufficient quotable spans or uncertain\n",
    "]\n",
    "\n",
    "class BottleneckEvidence(BaseModel):\n",
    "    \"\"\"\n",
    "    Structured judgment for PFM Bottleneck 6.1.\n",
    "    Follows precision-first rules: strong/moderate cues, hard negatives, and span extraction.\n",
    "    \"\"\"\n",
    "    # Primary decisions\n",
    "    is_fragmentation_evidence: bool = Field(\n",
    "        ..., description=\"Feature-based verdict (diagnostic). True iff STRONG>=1 or MODERATE>=2 and trigger_spans present and not hard_negative.\"\n",
    "    )\n",
    "    is_fragmentation_plus_failure: bool = Field(\n",
    "        ..., description=\"Consequence-based verdict. True iff is_fragmentation_evidence and failure_present.\"\n",
    "    )\n",
    "    decision: Decision = Field(\n",
    "        ..., description='Overall decision among {\"relevant_feature\",\"relevant_feature_and_failure\",\"irrelevant\",\"abstain\"}.'\n",
    "    )\n",
    "\n",
    "    # Evidence for fragmentation\n",
    "    strong_cues: List[StrongCue] = Field(default_factory=list, description=\"Which strong cues were found.\")\n",
    "    moderate_cues: List[ModerateCue] = Field(default_factory=list, description=\"Which moderate cues were found.\")\n",
    "    hard_negative: bool = Field(False, description=\"True if the passage matches any exclusion rule.\")\n",
    "    trigger_spans: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Verbatim phrases from the text that support fragmentation cues (must be substrings of the input).\",\n",
    "    )\n",
    "    subtype: Subtype = Field(\"other\", description=\"Subtype of fragmentation, if any.\")\n",
    "\n",
    "    # Evidence for failure/inefficiency\n",
    "    failure_present: bool = Field(False, description=\"True if explicit or clearly implied delivery failure/inefficiency is present.\")\n",
    "    failure_types: List[FailureType] = Field(default_factory=list, description=\"Categorization of the failure/inefficiency mentioned.\")\n",
    "    failure_spans: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"Verbatim phrases supporting failure/inefficiency (must be substrings of the input).\",\n",
    "    )\n",
    "\n",
    "    rationale: str = Field(\n",
    "        ...,\n",
    "        description=\"2-3 sentence justification referencing the trigger_spans/failure_spans; avoid speculation; no new facts.\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67ab234d-8af8-4065-82e8-9706709c4a23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#node_id, chunk_id, extended_context, extracted_evidence, expert_classification, reason_for_expert_irrelevant = df.sample().iloc[0].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7f32177-5840-4c50-b1a3-87b416c37e6b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f22c45fc-2fd3-4d5a-acb0-50967106b6cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "l = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4737dca-671d-4f79-aaf3-a623b33d6e52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "start, end = 150, df.shape[0]\n",
    "\n",
    "for item in tqdm(df.values.tolist()[start:end]):\n",
    "    node_id, chunk_id, extended_context, extracted_evidence, expert_classification, reason_for_expert_irrelevant = item\n",
    "    prompt = PROMPT_TEMPLATE.format(\n",
    "        challenge = challenge,\n",
    "        bottleneck = bottleneck,\n",
    "        extended_definition=extended_definition,\n",
    "        input_text=extracted_evidence,\n",
    "        extended_context=extended_context,\n",
    "    )\n",
    "    \n",
    "    output = service.execute(\n",
    "        prompt=prompt,\n",
    "        model=DEFAULT_LLM_MODEL,\n",
    "        response_model=BottleneckEvidence,\n",
    "        temperature=0.0,\n",
    "        system_message=system_prompt\n",
    "    )\n",
    "    l.append((node_id, chunk_id, extended_context, extracted_evidence, expert_classification, reason_for_expert_irrelevant, output, ))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8a8a2deb-277d-42fd-a98c-67c6d4650c52",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def relevance_boolean(x):\n",
    "    return x=='Relevant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98d5686f-03cf-4cc9-bcf8-18c503f42575",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = [(relevance_boolean(item[-3]), item[-1].is_fragmentation_evidence, item[-1].is_fragmentation_plus_failure) for item in l]\n",
    "df_results = pd.DataFrame(m, columns = ['expert_label', 'model1_label', 'model2_label'])\n",
    "precision_m1 = (\n",
    "    df_results.query(\"model1_label == True and expert_label == True\").shape[0]\n",
    "    / df_results.query(\"model1_label == True\").shape[0]\n",
    "    if df_results.query(\"model1_label == True\").shape[0] > 0\n",
    "    else 0\n",
    ")\n",
    "\n",
    "precision_m2 = (\n",
    "    df_results.query(\"model2_label == True and expert_label == True\").shape[0]\n",
    "    / df_results.query(\"model2_label == True\").shape[0]\n",
    "    if df_results.query(\"model2_label == True\").shape[0] > 0\n",
    "    else 0\n",
    ")\n",
    "\n",
    "print(f\"Precision (Model 1): {precision_m1:.2f}\")\n",
    "print(f\"Precision (Model 2): {precision_m2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c648b5c9-b679-40cc-a924-05da5b04960c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df['model1_label'] = df_results.model1_label.values.tolist()\n",
    "df['model2_label'] = df_results.model2_label.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3bcec60-e79d-41ee-8418-626ae4a98604",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9598eebc-e467-4be3-ae68-1ffbe2f364f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv('6_1_revised_extarction_validation_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2480dd8f-e158-42c7-9f3e-bde66e266dd8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "908c2413-a6b0-4a28-ba80-e7d8d9337469",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9edabc75-0a89-4460-8071-0be89eedac58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Run on the prefiltered list of 600 chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "34a38b99-b043-4ff5-aca6-1024738b058e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4ef0dc9-228f-4071-b2b1-a2202cfe136f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_chunks = pd.read_csv('per_pfr_chunks_with_prefilter_results.csv')\n",
    "df_rel_chunks = df_chunks[df_chunks.prefilter_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9e3183d-5dd4-4bb4-991f-06de555f1064",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The prefliter was done on the full chunk so we dont have the associated extracted evidence text. We first get this potential evidence\n",
    "class ConfidenceLevel(str, Enum):\n",
    "    strong = \"strong\"\n",
    "    borderline = \"borderline\"\n",
    "    weak = \"weak\"\n",
    "\n",
    "class BottleneckBase(BaseModel):\n",
    "    confidence: Optional[ConfidenceLevel] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"How confidently the extracted evidence supports the bottleneck. \"\n",
    "            \"Choose 'strong' if the evidence clearly and directly supports the bottleneck, \"\n",
    "            \"'borderline' if it is somewhat relevant but may be open to interpretation, \"\n",
    "            \"and 'weak' if the evidence is tenuous, ambiguous, or only indirectly related.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "class Bottleneck_2_1(BottleneckBase):\n",
    "    extracted_evidence: Optional[str] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Verbatim excerpt from the text that provides concrete evidence of fragmented, inconsistent, or uncoordinated policy design. \"\n",
    "            \"Look for examples of conflicting mandates, duplicative schemes, lack of alignment across sectors or institutions, or absence of cross-sector coordination mechanisms. \"\n",
    "            \"Do not extract vague critiques of policy or general governance weakness without explicit reference to inter-policy inconsistency or siloed formulation. \"\n",
    "            \"Use only direct text from the source; do not paraphrase or infer.\"\n",
    "        )\n",
    "    )\n",
    "    reasoning: Optional[str] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Brief explanation of how the extracted text illustrates fragmented or uncoordinated policy design. \"\n",
    "            \"The reasoning should clarify why the excerpt demonstrates lack of alignment or duplication, and avoid interpretation beyond the quoted material.\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "def make_bottleneck_prompt(text: str) -> str:\n",
    "\n",
    "    return f\"\"\"\n",
    "        You are analyzing a public finance document to identify specific bottlenecks affecting development outcomes.\n",
    "        \n",
    "        The context for your analysis is as follows:\n",
    "        \n",
    "        Role of Public Finance: Effective Resource Mobilization & Distribution\n",
    "        role_description: Governments need to raise and allocate and influence private financial resources in support of the pursuit of their policy objectives, ensuring both that sufficient resources are available when needed, and that these are allocated according to needs and cost-effectiveness criteria. How governments do this has important distributional impacts and can influence public and private behaviour towards achievement of objectives.\n",
    "        \n",
    "        PFM Challenge: Unreliable, delayed and fragmented funding for delivery\n",
    "        → challenge_description: Assesses how predictable, timely, and well-coordinated funding flows are, and whether fragmentation or delays impede delivery\n",
    "        \n",
    "        Specific Bottleneck: Ad hoc, Political and Fragmented Funding Channels\n",
    "        → bottleneck description: Governments and public sector entities often rely on multiple, uncoordinated funding mechanisms—such as general funds, earmarked revenues, donor funding, and intergovernmental transfers. These mechanisms often lack integration, leading to volatility, administrative duplication, and fragmented service delivery. Discretionary or politically influenced allocation, parallel management systems (especially from donors), and poor coordination across agencies or levels of government compound inefficiencies. Common issues include delays, incomplete disbursements, excessive reporting burdens, and poor alignment of funding with long-term plans or shared objectives.\n",
    "        \n",
    "        ---\n",
    "        \n",
    "        Your task:\n",
    "        \n",
    "        - Carefully read the excerpt below.\n",
    "        - Extract direct evidence from the text that clearly supports the presence of the specific bottleneck listed above.\n",
    "        - Only extract text that is explicitly present in the excerpt.\n",
    "        - Do not infer, assume, or include information that is not stated.\n",
    "        - If you find no clear evidence, return null.\n",
    "        \n",
    "        For each piece of extracted evidence, briefly explain your reasoning (i.e., why this excerpt indicates the bottleneck), and indicate if the match is ambiguous.\n",
    "        \n",
    "        Text to analyze:\n",
    "        \n",
    "        {text}\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "281bed2e-c233-4eea-b644-ef675493f70d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "DEFAULT_SYSTEM_PROMPT = '''You are a public finance expert working with a multilateral development institution.\n",
    "\n",
    "    Your task is to carefully read and analyze Public Finance Review (PFR) documents, budget support documents, or other fiscal diagnostics and project reports produced by institutions such as the World Bank or IMF.\n",
    "\n",
    "    You are trained to identify and extract supporting evidence for specific Public Financial Management (PFM) bottlenecks, based on a predefined set of challenges and bottlenecks.\n",
    "\n",
    "    The evidence may appear in explicit or implicit form. You should be attentive to:\n",
    "    - Descriptions of institutional weakness or fragmentation\n",
    "    - Observations about policy design vs implementation\n",
    "    - Statements about fiscal sustainability, resource adequacy, or funding flows\n",
    "    - Structural, capacity-related, or political-economy constraints\n",
    "    - Trends, examples, or observations—both qualitative and quantitative\n",
    "\n",
    "    You will return evidence *only if it clearly supports the described bottleneck*, otherwise leave it blank.\n",
    "\n",
    "    Be concise but specific. Use quotes from the document when possible or summarize tightly if quoting is impractical.\n",
    "    '''\n",
    "l = []\n",
    "\n",
    "for item in tqdm(df_rel_chunks.iterrows()):\n",
    "    node_id, chunk_id, text, _ = item[1]\n",
    "    prompt = make_bottleneck_prompt(text=text)\n",
    "    result = service.execute(\n",
    "        prompt=prompt,\n",
    "        model=DEFAULT_LLM_MODEL,\n",
    "        response_model=Bottleneck_2_1,\n",
    "        temperature=0.0,\n",
    "        system_message=DEFAULT_SYSTEM_PROMPT\n",
    "    )\n",
    "    if result.extracted_evidence:\n",
    "        l.append(item[1].values.tolist()+[result.extracted_evidence])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11b30e04-b93d-4ce1-b34a-9172d44ab762",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cols =  ['node_id', 'chunk_id', 'chunk', 'prefilter_tag', 'extracted_evidence']\n",
    "ddf = pd.DataFrame(l, columns =cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3885558-7fcf-47b5-b08b-dc98d4992b13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ddf.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3af1e82-eb79-49dc-afff-47828be875ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "new_output = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e3a95df-d33a-43ff-b0fc-a7f926a896f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# run the revised validation model on these chunks\n",
    "\n",
    "start, end = 300, ddf.shape[0]\n",
    "\n",
    "for item in tqdm(ddf.values.tolist()[start:end]):\n",
    "    node_id, chunk_id, extended_context, _, extracted_evidence = item\n",
    "    prompt = PROMPT_TEMPLATE.format(\n",
    "        challenge = challenge,\n",
    "        bottleneck = bottleneck,\n",
    "        extended_definition=extended_definition,\n",
    "        input_text=extracted_evidence,\n",
    "        extended_context=extended_context,\n",
    "    )\n",
    "    \n",
    "    output = service.execute(\n",
    "        prompt=prompt,\n",
    "        model=DEFAULT_LLM_MODEL,\n",
    "        response_model=BottleneckEvidence,\n",
    "        temperature=0.0,\n",
    "        system_message=system_prompt\n",
    "    )\n",
    "    new_output.append((node_id, chunk_id, extended_context, extracted_evidence, output))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fdf7901-432c-4729-8989-740d4e5f12d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ddf['model1_label'] = [item[-1].is_fragmentation_evidence for item in new_output]\n",
    "ddf['model2_label'] = [item[-1].is_fragmentation_plus_failure for item in new_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "35d6d2d8-e909-4782-8302-2dc8a34782db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ddf.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d68b1529-3b15-4a98-94aa-01d159eb1fae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ddf.to_csv('prefiltered_6_1_extraction_validation_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5d5a3903-c4ee-45ef-8150-acad9fb7aaf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "ddf.model1_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4354b3b5-d9c8-4eba-b7b0-93d4af73c27f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "6_1ad_hoc_funding_extraction_validation",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Witchcraft Cases",
   "language": "python",
   "name": "witchcraft"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
